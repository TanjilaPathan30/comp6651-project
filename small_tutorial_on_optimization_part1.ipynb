{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TanjilaPathan30/comp6651-project/blob/main/small_tutorial_on_optimization_part1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Iris dataset"
      ],
      "metadata": {
        "id": "78IwcuHT9LMs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IIsj8bjR87wP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Iris dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Filter for binary classification (only class 0 and class 1)\n",
        "binary_class_indices = y <= 1\n",
        "X = X[binary_class_indices]\n",
        "y = y[binary_class_indices]\n",
        "\n",
        "# Convert to torch tensors\n",
        "X = torch.tensor(X, dtype=torch.float32)\n",
        "y = torch.tensor(y, dtype=torch.int64)"
      ],
      "metadata": {
        "id": "DZzQKDRv915q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spliting the dataset"
      ],
      "metadata": {
        "id": "6FM0mAlO96d8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "seed = 15\n",
        "# Split the dataset\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state= seed)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=seed)\n",
        "\n",
        "print(f'Train size: {len(X_train)}, Validation size: {len(X_val)}, Test size: {len(X_test)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bki1FfsE945C",
        "outputId": "b2d57e02-1af8-4013-b44a-76f89431f859"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 60, Validation size: 20, Test size: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the model"
      ],
      "metadata": {
        "id": "tMBgXbS8-ILI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize weights and bias\n",
        "weights = torch.randn(X_train.shape[1], requires_grad=True)\n",
        "bias = torch.randn(1, requires_grad=True)\n",
        "\n",
        "# Sigmoid function\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + torch.exp(-x))\n",
        "\n",
        "# Logistic regression model\n",
        "def model(X):\n",
        "    return sigmoid(X @ weights + bias)"
      ],
      "metadata": {
        "id": "L-y8L2HD-Hom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model"
      ],
      "metadata": {
        "id": "D3tkNuVo-Qnm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "    predicted = (y_pred > 0.5).float()\n",
        "    return (predicted == y_true).float().mean()\n",
        "\n",
        "# Hyperparameters\n",
        "learning_rate = 0.01\n",
        "epochs = 1000\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    # Forward pass on training set\n",
        "    y_train_pred = model(X_train).squeeze()\n",
        "\n",
        "    # Binary cross-entropy loss\n",
        "    loss = -(y_train * torch.log(y_train_pred) + (1 - y_train) * torch.log(1 - y_train_pred)).mean()\n",
        "\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    # Update weights and bias manually\n",
        "    with torch.no_grad():\n",
        "        weights -= learning_rate * weights.grad\n",
        "        bias -= learning_rate * bias.grad\n",
        "\n",
        "    grad_norm = torch.norm(weights.grad)\n",
        "    # Zero gradients after updating\n",
        "    weights.grad.zero_()\n",
        "    bias.grad.zero_()\n",
        "\n",
        "    # Validation evaluation\n",
        "    with torch.no_grad():\n",
        "        y_val_pred = model(X_val).squeeze()\n",
        "        val_loss = -(y_val * torch.log(y_val_pred) + (1 - y_val) * torch.log(1 - y_val_pred)).mean()\n",
        "        val_acc = accuracy(y_val, y_val_pred)\n",
        "\n",
        "    # Print progress every 100 epochs\n",
        "    if epoch % 100 == 0:\n",
        "        print(f'Epoch {epoch}, gradient norm: {grad_norm.item():.4f}')\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}, Val Accuracy: {val_acc.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDK09q5h-UhC",
        "outputId": "189c88d9-b77f-4011-800f-62efc7e707e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, gradient norm: 0.8232\n",
            "Epoch 0, Loss: 0.7219, Val Loss: 0.8088, Val Accuracy: 0.4500\n",
            "Epoch 100, gradient norm: 0.4322\n",
            "Epoch 100, Loss: 0.4226, Val Loss: 0.4501, Val Accuracy: 1.0000\n",
            "Epoch 200, gradient norm: 0.3080\n",
            "Epoch 200, Loss: 0.2870, Val Loss: 0.2997, Val Accuracy: 1.0000\n",
            "Epoch 300, gradient norm: 0.2343\n",
            "Epoch 300, Loss: 0.2138, Val Loss: 0.2194, Val Accuracy: 1.0000\n",
            "Epoch 400, gradient norm: 0.1873\n",
            "Epoch 400, Loss: 0.1694, Val Loss: 0.1712, Val Accuracy: 1.0000\n",
            "Epoch 500, gradient norm: 0.1554\n",
            "Epoch 500, Loss: 0.1399, Val Loss: 0.1395, Val Accuracy: 1.0000\n",
            "Epoch 600, gradient norm: 0.1324\n",
            "Epoch 600, Loss: 0.1191, Val Loss: 0.1173, Val Accuracy: 1.0000\n",
            "Epoch 700, gradient norm: 0.1153\n",
            "Epoch 700, Loss: 0.1037, Val Loss: 0.1009, Val Accuracy: 1.0000\n",
            "Epoch 800, gradient norm: 0.1020\n",
            "Epoch 800, Loss: 0.0918, Val Loss: 0.0884, Val Accuracy: 1.0000\n",
            "Epoch 900, gradient norm: 0.0914\n",
            "Epoch 900, Loss: 0.0824, Val Loss: 0.0786, Val Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate on the test set"
      ],
      "metadata": {
        "id": "1gZe3o5o-aTn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on test set\n",
        "with torch.no_grad():\n",
        "    y_test_pred = model(X_test).squeeze()\n",
        "    test_acc = accuracy(y_test, y_test_pred)\n",
        "    print(f'Test Accuracy: {test_acc.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldvk45d5-Yuq",
        "outputId": "caf54ae0-cc1f-4334-f08d-4e3c175f8244"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 1.0000\n"
          ]
        }
      ]
    }
  ]
}